{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTOqNHu6FCLQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import glob\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "import pathlib\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "-KEXqwMGFEmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "id": "o2bOl6E0FEpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/test')"
      ],
      "metadata": {
        "id": "JXDud4o5FErx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer=transforms.Compose([\n",
        "    transforms.Resize((227,227)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\n",
        "                        [0.5,0.5,0.5])\n",
        "])"
      ],
      "metadata": {
        "id": "ma5DOrBvFEt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "num_classes = 2\n",
        "learning_rate = 0.01\n",
        "num_epochs = 10"
      ],
      "metadata": {
        "id": "b8hJdov8FEwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision.transforms import Compose, ToTensor, Resize\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_val_dataset(dataset, prvi=0.25,drugi=0.50):\n",
        "    train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=prvi)\n",
        "   \n",
        "    datasets = {}\n",
        "    datasets['train'] = Subset(dataset, train_idx)\n",
        "    datasets['val'] = Subset(dataset, val_idx)\n",
        "\n",
        "    trainlo_idx, test_idx = train_test_split(list(range(len(datasets['val']))), test_size=drugi)\n",
        "    datasets['val'] = Subset(dataset, trainlo_idx)\n",
        "    datasets['test'] = Subset(dataset, test_idx)\n",
        "    return datasets\n",
        "\n",
        "dataset = ImageFolder('/content/test/MyDrive/LISTOVI-SVI', transform=transformer)\n",
        "print(len(dataset))\n",
        "datasets = train_val_dataset(dataset)\n",
        "print(len(datasets['train']))\n",
        "print(len(datasets['val']))\n",
        "print(len(datasets['test']))\n",
        "\n",
        "print(datasets['train'].dataset)\n",
        "\n",
        "dataloaders = {x:DataLoader(datasets[x],16, shuffle=True) for x in ['train','val','test']}\n",
        "x,y = next(iter(dataloaders['train']))\n",
        "print(x.shape, y.shape)"
      ],
      "metadata": {
        "id": "Y5iPa1nOFEyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(datasets['train'], batch_size=16, shuffle=True)\n",
        "train_loader\n",
        "validation_loader = DataLoader(datasets['val'], batch_size=16, shuffle=True)\n",
        "validation_loader\n",
        "test_loader = DataLoader(datasets['test'], batch_size=16, shuffle=True)\n",
        "test_loader"
      ],
      "metadata": {
        "id": "rLRbf4RUFE0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train data set:', len(train_loader))\n",
        "print('Test data set:', len(validation_loader))\n",
        "print('Test data set:', len(test_loader))"
      ],
      "metadata": {
        "id": "5iFUU4RlFE2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes=['diseased', 'helthy']\n",
        "print(classes)"
      ],
      "metadata": {
        "id": "9t9KSSjfFhIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "__all__ = ['DenseNet', 'densenet121', 'densenet169', 'densenet201', 'densenet161']\n",
        "\n",
        "model_urls = {\n",
        "    'densenet121': 'https://download.pytorch.org/models/densenet121-a639ec97.pth',\n",
        "    'densenet169': 'https://download.pytorch.org/models/densenet169-b2777c0a.pth',\n",
        "    'densenet201': 'https://download.pytorch.org/models/densenet201-c1103571.pth',\n",
        "    'densenet161': 'https://download.pytorch.org/models/densenet161-8d451a50.pth',\n",
        "}\n",
        "\n",
        "\n",
        "class _DenseLayer(nn.Module):\n",
        "    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate, memory_efficient=False):\n",
        "        super(_DenseLayer, self).__init__()\n",
        "        self.add_module('norm1', nn.BatchNorm2d(num_input_features)),\n",
        "        self.add_module('relu1', nn.ReLU(inplace=True)),\n",
        "        self.add_module('conv1', nn.Conv2d(num_input_features, bn_size *\n",
        "                                           growth_rate, kernel_size=1, stride=1,\n",
        "                                           bias=False)),\n",
        "        self.add_module('norm2', nn.BatchNorm2d(bn_size * growth_rate)),\n",
        "        self.add_module('relu2', nn.ReLU(inplace=True)),\n",
        "        self.add_module('conv2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
        "                                           kernel_size=3, stride=1, padding=1,\n",
        "                                           bias=False)),\n",
        "        self.drop_rate = float(drop_rate)\n",
        "        self.memory_efficient = memory_efficient\n",
        "\n",
        "    def bn_function(self, inputs):\n",
        "        # type: (List[Tensor]) -> Tensor\n",
        "        concated_features = torch.cat(inputs, 1)\n",
        "        bottleneck_output = self.conv1(self.relu1(self.norm1(concated_features)))  # noqa: T484\n",
        "        return bottleneck_output\n",
        "\n",
        "    # todo: rewrite when torchscript supports any\n",
        "    def any_requires_grad(self, input):\n",
        "        # type: (List[Tensor]) -> bool\n",
        "        for tensor in input:\n",
        "            if tensor.requires_grad:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    @torch.jit.unused  # noqa: T484\n",
        "    def call_checkpoint_bottleneck(self, input):\n",
        "        # type: (List[Tensor]) -> Tensor\n",
        "        def closure(*inputs):\n",
        "            return self.bn_function(inputs)\n",
        "\n",
        "        return cp.checkpoint(closure, *input)\n",
        "\n",
        "    @torch.jit._overload_method  # noqa: F811\n",
        "    def forward(self, input):\n",
        "        # type: (List[Tensor]) -> (Tensor)\n",
        "        pass\n",
        "\n",
        "    @torch.jit._overload_method  # noqa: F811\n",
        "    def forward(self, input):\n",
        "        # type: (Tensor) -> (Tensor)\n",
        "        pass\n",
        "\n",
        "    # torchscript does not yet support *args, so we overload method\n",
        "    # allowing it to take either a List[Tensor] or single Tensor\n",
        "    def forward(self, input):  # noqa: F811\n",
        "        if isinstance(input, Tensor):\n",
        "            prev_features = [input]\n",
        "        else:\n",
        "            prev_features = input\n",
        "\n",
        "        if self.memory_efficient and self.any_requires_grad(prev_features):\n",
        "            if torch.jit.is_scripting():\n",
        "                raise Exception(\"Memory Efficient not supported in JIT\")\n",
        "\n",
        "            bottleneck_output = self.call_checkpoint_bottleneck(prev_features)\n",
        "        else:\n",
        "            bottleneck_output = self.bn_function(prev_features)\n",
        "\n",
        "        new_features = self.conv2(self.relu2(self.norm2(bottleneck_output)))\n",
        "        if self.drop_rate > 0:\n",
        "            new_features = F.dropout(new_features, p=self.drop_rate,\n",
        "                                     training=self.training)\n",
        "        return new_features\n",
        "\n",
        "\n",
        "class _DenseBlock(nn.ModuleDict):\n",
        "    _version = 2\n",
        "\n",
        "    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate, memory_efficient=False):\n",
        "        super(_DenseBlock, self).__init__()\n",
        "        for i in range(num_layers):\n",
        "            layer = _DenseLayer(\n",
        "                num_input_features + i * growth_rate,\n",
        "                growth_rate=growth_rate,\n",
        "                bn_size=bn_size,\n",
        "                drop_rate=drop_rate,\n",
        "                memory_efficient=memory_efficient,\n",
        "            )\n",
        "            self.add_module('denselayer%d' % (i + 1), layer)\n",
        "\n",
        "    def forward(self, init_features):\n",
        "        features = [init_features]\n",
        "        for name, layer in self.items():\n",
        "            new_features = layer(features)\n",
        "            features.append(new_features)\n",
        "        return torch.cat(features, 1)\n",
        "\n",
        "\n",
        "class _Transition(nn.Sequential):\n",
        "    def __init__(self, num_input_features, num_output_features):\n",
        "        super(_Transition, self).__init__()\n",
        "        self.add_module('norm', nn.BatchNorm2d(num_input_features))\n",
        "        self.add_module('relu', nn.ReLU(inplace=True))\n",
        "        self.add_module('conv', nn.Conv2d(num_input_features, num_output_features,\n",
        "                                          kernel_size=1, stride=1, bias=False))\n",
        "        self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "\n",
        "class DenseNet(nn.Module):\n",
        "    r\"\"\"Densenet-BC model class, based on\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "    Args:\n",
        "        growth_rate (int) - how many filters to add each layer (`k` in paper)\n",
        "        block_config (list of 4 ints) - how many layers in each pooling block\n",
        "        num_init_features (int) - the number of filters to learn in the first convolution layer\n",
        "        bn_size (int) - multiplicative factor for number of bottle neck layers\n",
        "          (i.e. bn_size * k features in the bottleneck layer)\n",
        "        drop_rate (float) - dropout rate after each dense layer\n",
        "        num_classes (int) - number of classification classes\n",
        "        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\n",
        "          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16),\n",
        "                 num_init_features=64, bn_size=4, drop_rate=0, num_classes=1000, memory_efficient=False):\n",
        "\n",
        "        super(DenseNet, self).__init__()\n",
        "\n",
        "        # First convolution\n",
        "        self.features = nn.Sequential(OrderedDict([\n",
        "            ('conv0', nn.Conv2d(3, num_init_features, kernel_size=7, stride=2,\n",
        "                                padding=3, bias=False)),\n",
        "            ('norm0', nn.BatchNorm2d(num_init_features)),\n",
        "            ('relu0', nn.ReLU(inplace=True)),\n",
        "            ('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
        "        ]))\n",
        "\n",
        "        # Each denseblock\n",
        "        num_features = num_init_features\n",
        "        for i, num_layers in enumerate(block_config):\n",
        "            block = _DenseBlock(\n",
        "                num_layers=num_layers,\n",
        "                num_input_features=num_features,\n",
        "                bn_size=bn_size,\n",
        "                growth_rate=growth_rate,\n",
        "                drop_rate=drop_rate,\n",
        "                memory_efficient=memory_efficient\n",
        "            )\n",
        "            self.features.add_module('denseblock%d' % (i + 1), block)\n",
        "            num_features = num_features + num_layers * growth_rate\n",
        "            if i != len(block_config) - 1:\n",
        "                trans = _Transition(num_input_features=num_features,\n",
        "                                    num_output_features=num_features // 2)\n",
        "                self.features.add_module('transition%d' % (i + 1), trans)\n",
        "                num_features = num_features // 2\n",
        "\n",
        "        # Final batch norm\n",
        "        self.features.add_module('norm5', nn.BatchNorm2d(num_features))\n",
        "\n",
        "        # Linear layer\n",
        "        self.classifier = nn.Linear(num_features, num_classes)\n",
        "\n",
        "        # Official init from torch repo.\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.features(x)\n",
        "        out = F.relu(features, inplace=True)\n",
        "        out = F.adaptive_avg_pool2d(out, (1, 1))\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def _load_state_dict(model, model_url, progress):\n",
        "    # '.'s are no longer allowed in module names, but previous _DenseLayer\n",
        "    # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
        "    # They are also in the checkpoints in model_urls. This pattern is used\n",
        "    # to find such keys.\n",
        "    pattern = re.compile(\n",
        "        r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "\n",
        "    state_dict = load_state_dict_from_url(model_url, progress=progress)\n",
        "    for key in list(state_dict.keys()):\n",
        "        res = pattern.match(key)\n",
        "        if res:\n",
        "            new_key = res.group(1) + res.group(2)\n",
        "            state_dict[new_key] = state_dict[key]\n",
        "            del state_dict[key]\n",
        "    model.load_state_dict(state_dict)\n",
        "\n",
        "\n",
        "def _densenet(arch, growth_rate, block_config, num_init_features, pretrained, progress,\n",
        "              **kwargs):\n",
        "    model = DenseNet(growth_rate, block_config, num_init_features, **kwargs)\n",
        "    if pretrained:\n",
        "        _load_state_dict(model, model_urls[arch], progress)\n",
        "    return model\n",
        "\n",
        "\n",
        "def densenet121(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"Densenet-121 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\n",
        "          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_\n",
        "    \"\"\"\n",
        "    return _densenet('densenet121', 32, (6, 12, 24, 16), 64, pretrained, progress,\n",
        "                     **kwargs)\n",
        "\n",
        "\n",
        "def densenet161(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"Densenet-161 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\n",
        "          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_\n",
        "    \"\"\"\n",
        "    return _densenet('densenet161', 48, (6, 12, 36, 24), 96, pretrained, progress,\n",
        "                     **kwargs)\n",
        "\n",
        "\n",
        "def densenet169(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"Densenet-169 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\n",
        "          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_\n",
        "    \"\"\"\n",
        "    return _densenet('densenet169', 32, (6, 12, 32, 32), 64, pretrained, progress,\n",
        "                     **kwargs)\n",
        "\n",
        "\n",
        "def densenet201(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"Densenet-201 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\n",
        "          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_\n",
        "    \"\"\"\n",
        "    return _densenet('densenet201', 32, (6, 12, 48, 32), 64, pretrained, progress,\n",
        "                     **kwargs)"
      ],
      "metadata": {
        "id": "8pVhuu6OFhK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "model = AlexNet(num_classes=2).to(device)\n",
        "\n",
        "#Setting the loss function\n",
        "cost = nn.CrossEntropyLoss()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#Setting the optimizer with the model parameters and learning rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "#this is defined to print how many steps are remaining when training\n",
        "total_step = len(train_loader)"
      ],
      "metadata": {
        "id": "CTGkvrG2FhNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "epochs = 10\n",
        "min_valid_loss = np.inf\n",
        "val_losses = []\n",
        "train_losses = []\n",
        "for e in range(epochs):\n",
        "    train_loss = 0.0\n",
        "    model.train()     # Optional when not using Model Specific layer\n",
        "    for data, labels in train_loader:\n",
        "        if torch.cuda.is_available():\n",
        "            data, labels = data.cuda(), labels.cuda()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        target = model(data)\n",
        "        loss = criterion(target,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    \n",
        "    valid_loss = 0.0\n",
        "  \n",
        "\n",
        "    model.eval()     # Optional when not using Model Specific layer\n",
        "    for data, labels in validation_loader:\n",
        "        if torch.cuda.is_available():\n",
        "            data, labels = data.cuda(), labels.cuda()\n",
        "        \n",
        "        target = model(data)\n",
        "        loss = criterion(target,labels)\n",
        "        valid_loss = loss.item() * data.size(0)\n",
        "        \n",
        " \n",
        "\n",
        "    train_losses.append((train_loss / len(train_loader)))\n",
        "    val_losses.append((valid_loss / len(validation_loader)))\n",
        "\n",
        "\n",
        "    print(f'Epoch {e+1} \\t\\t Training Loss: {train_loss / len(train_loader)} \\t\\t Validation Loss: {valid_loss / len(validation_loader)}')\n",
        "    if min_valid_loss > valid_loss:\n",
        "        print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
        "        min_valid_loss = valid_loss\n",
        "        # Saving State Dict\n",
        "        torch.save(model.state_dict(), 'saved_model.pth')\n"
      ],
      "metadata": {
        "id": "_oRIgVzjFhPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "plt.plot(val_losses,label=\"val\")\n",
        "plt.plot(train_losses,label=\"train\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ziw-9Qf6FhRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "model = AlexNet(num_classes=3).to(device)\n",
        "\n",
        "#Setting the loss function\n",
        "cost = nn.CrossEntropyLoss()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#Setting the optimizer with the model parameters and learning rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "#this is defined to print how many steps are remaining when training\n",
        "total_step = len(train_loader)"
      ],
      "metadata": {
        "id": "Du0ew_DPFhT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(3):\n",
        "    for i, (images, labels) in enumerate(train_loader):  \n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        #Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = cost(outputs, labels)\n",
        "        \t\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \t\t\n",
        "        if (i+1) % 15 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "        \t\t           .format(epoch+1, 7, i+1, total_step, loss.item()))\n",
        "                       \n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for data in tqdm(test_loader):\n",
        "  images,labels=data[0].to(device),data[1]  \n",
        "  y_true.extend(labels.numpy())\n",
        " \n",
        "  outputs=model(images)\n",
        " \n",
        "  _, predicted = torch.max(outputs, 1)\n",
        "  y_pred.extend(predicted.cpu().numpy())\n",
        "f1_score(y_true, y_pred, average='macro')\n",
        "print(f1_score(y_true, y_pred, average='macro'))\n",
        "\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
        "\t "
      ],
      "metadata": {
        "id": "Izs08kbMFrSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics\n",
        "\n",
        "print(\"f1 score\",f1_score(y_true, y_pred, average='macro'))\n",
        "print(\"f1 score\",f1_score(y_true, y_pred, average='micro'))\n",
        "print(\"accuracy_score\",sklearn.metrics.accuracy_score(y_true, y_pred))\n",
        "print(\"balanced accuracy_score\",sklearn.metrics.balanced_accuracy_score(y_true, y_pred))\n",
        "print(\"precision_score\",sklearn.metrics.precision_score(y_true, y_pred, average='macro'))\n",
        "print(\"rECALL micro\",sklearn.metrics.recall_score(y_true, y_pred, average='micro'))\n",
        "print(\"rECALL macro\",sklearn.metrics.recall_score(y_true, y_pred, average='macro'))"
      ],
      "metadata": {
        "id": "WdcVJaCVFtEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        " \n",
        "for data in tqdm(test_loader):\n",
        "  images,labels=data[0].to(device),data[1]  \n",
        "  y_true.extend(labels.numpy())\n",
        " \n",
        "  outputs=model(images)\n",
        " \n",
        "  _, predicted = torch.max(outputs, 1)\n",
        "  y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "class_names = ('angular_leaf_spot', 'bean_rust', 'healthy')\n",
        "dataframe = pd.DataFrame(cf_matrix, index=class_names, columns=class_names)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        " \n",
        "# Create heatmap\n",
        "sns.heatmap(dataframe, annot=True, cbar=None,cmap=\"YlGnBu\",fmt=\"d\")\n",
        " \n",
        "plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
        " \n",
        "plt.ylabel(\"True Class\"), \n",
        "plt.xlabel(\"Predicted Class\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "unOySFTfFuAR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}